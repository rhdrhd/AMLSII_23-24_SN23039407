{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "from rich.progress import Progress\n",
    "import timm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  \n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "seed_everything(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINE DATASET\n",
    "ROOT = 'Datasets'\n",
    "TRAIN_IMAGES_PATH = os.path.join(ROOT, 'train_images')\n",
    "train_df = pd.read_csv(os.path.join(ROOT, 'train.csv'))\n",
    "train_df['path'] = TRAIN_IMAGES_PATH + '/' + train_df['image_id']\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)  # Reset the index\n",
    "        #self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #print(\"index is \" , index)\n",
    "        if index >= len(self.df):\n",
    "            raise IndexError('Index out of range')\n",
    "        img = Image.open(self.df['path'][index])\n",
    "        #img = np.array(img)\n",
    "        label = torch.tensor(self.df['label'][index], dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 128 #224 for ViT\n",
    "HEIGHT = 128 #224\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 16\n",
    "model_name = \"efficientnet_b0\"\n",
    "num_epochs = 2\n",
    "patience = 3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    \n",
    "    if name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_feat = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Sequential(\n",
    "              nn.Linear(in_feat, NUM_CLASSES)\n",
    "              )\n",
    "    elif name ==\"efficientnet_b0\":\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_classes = 5  \n",
    "        classifier_input_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_features, num_classes) \n",
    "        )\n",
    "    elif name ==\"efficientnet_b3\":\n",
    "        model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_classes = 5  \n",
    "        classifier_input_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_features, num_classes) \n",
    "        )\n",
    "    elif name == \"efficientnet_b4\":\n",
    "        model = timm.create_model('tf_efficientnet_b4_ns',pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_classes = 5  \n",
    "        classifier_input_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_features, num_classes)\n",
    "        )\n",
    "    elif name == \"vit\":\n",
    "        model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        num_classes = 5\n",
    "\n",
    "        classifier_input_features = model.head.in_features\n",
    "        model.head = nn.Linear(classifier_input_features, num_classes)\n",
    "        \n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform =  transforms.Compose([\n",
    "    transforms.RandomResizedCrop((WIDTH, HEIGHT)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image_id  label                                  path  fold\n",
      "0      1000015157.jpg      0  Datasets/train_images/1000015157.jpg   1.0\n",
      "1      1000201771.jpg      3  Datasets/train_images/1000201771.jpg   1.0\n",
      "2       100042118.jpg      1   Datasets/train_images/100042118.jpg   3.0\n",
      "3      1000723321.jpg      1  Datasets/train_images/1000723321.jpg   1.0\n",
      "4      1000812911.jpg      3  Datasets/train_images/1000812911.jpg   1.0\n",
      "...               ...    ...                                   ...   ...\n",
      "17112   998910982.jpg      1   Datasets/train_images/998910982.jpg   1.0\n",
      "17113   999068805.jpg      3   Datasets/train_images/999068805.jpg   3.0\n",
      "17114   999329392.jpg      3   Datasets/train_images/999329392.jpg   3.0\n",
      "17115   999474432.jpg      1   Datasets/train_images/999474432.jpg   1.0\n",
      "17116   999998473.jpg      4   Datasets/train_images/999998473.jpg   4.0\n",
      "\n",
      "[17117 rows x 4 columns]\n",
      "fold is  1 epoch is  1\n",
      "torch.Size([16, 3, 128, 128])\n",
      "fold is  1 epoch is  2\n",
      "torch.Size([16, 3, 128, 128])\n",
      "             image_id  label                                  path  fold\n",
      "0       100042118.jpg      1   Datasets/train_images/100042118.jpg   3.0\n",
      "1      1000837476.jpg      3  Datasets/train_images/1000837476.jpg   2.0\n",
      "2      1000910826.jpg      2  Datasets/train_images/1000910826.jpg   4.0\n",
      "3      1001723730.jpg      4  Datasets/train_images/1001723730.jpg   3.0\n",
      "4      1001742395.jpg      3  Datasets/train_images/1001742395.jpg   3.0\n",
      "...               ...    ...                                   ...   ...\n",
      "17112   997973414.jpg      1   Datasets/train_images/997973414.jpg   4.0\n",
      "17113   999068805.jpg      3   Datasets/train_images/999068805.jpg   3.0\n",
      "17114   999329392.jpg      3   Datasets/train_images/999329392.jpg   3.0\n",
      "17115   999616605.jpg      4   Datasets/train_images/999616605.jpg   0.0\n",
      "17116   999998473.jpg      4   Datasets/train_images/999998473.jpg   4.0\n",
      "\n",
      "[17117 rows x 4 columns]\n",
      "fold is  2 epoch is  1\n",
      "torch.Size([16, 3, 128, 128])\n",
      "fold is  2 epoch is  2\n",
      "torch.Size([16, 3, 128, 128])\n",
      "             image_id  label                                  path  fold\n",
      "0      1000015157.jpg      0  Datasets/train_images/1000015157.jpg   1.0\n",
      "1      1000201771.jpg      3  Datasets/train_images/1000201771.jpg   1.0\n",
      "2       100042118.jpg      1   Datasets/train_images/100042118.jpg   3.0\n",
      "3      1000723321.jpg      1  Datasets/train_images/1000723321.jpg   1.0\n",
      "4      1000812911.jpg      3  Datasets/train_images/1000812911.jpg   1.0\n",
      "...               ...    ...                                   ...   ...\n",
      "17113   999068805.jpg      3   Datasets/train_images/999068805.jpg   3.0\n",
      "17114   999329392.jpg      3   Datasets/train_images/999329392.jpg   3.0\n",
      "17115   999474432.jpg      1   Datasets/train_images/999474432.jpg   1.0\n",
      "17116   999616605.jpg      4   Datasets/train_images/999616605.jpg   0.0\n",
      "17117   999998473.jpg      4   Datasets/train_images/999998473.jpg   4.0\n",
      "\n",
      "[17118 rows x 4 columns]\n",
      "fold is  3 epoch is  1\n",
      "torch.Size([16, 3, 128, 128])\n",
      "fold is  3 epoch is  2\n",
      "torch.Size([16, 3, 128, 128])\n",
      "             image_id  label                                  path  fold\n",
      "0      1000015157.jpg      0  Datasets/train_images/1000015157.jpg   1.0\n",
      "1      1000201771.jpg      3  Datasets/train_images/1000201771.jpg   1.0\n",
      "2      1000723321.jpg      1  Datasets/train_images/1000723321.jpg   1.0\n",
      "3      1000812911.jpg      3  Datasets/train_images/1000812911.jpg   1.0\n",
      "4      1000837476.jpg      3  Datasets/train_images/1000837476.jpg   2.0\n",
      "...               ...    ...                                   ...   ...\n",
      "17113   997973414.jpg      1   Datasets/train_images/997973414.jpg   4.0\n",
      "17114   998910982.jpg      1   Datasets/train_images/998910982.jpg   1.0\n",
      "17115   999474432.jpg      1   Datasets/train_images/999474432.jpg   1.0\n",
      "17116   999616605.jpg      4   Datasets/train_images/999616605.jpg   0.0\n",
      "17117   999998473.jpg      4   Datasets/train_images/999998473.jpg   4.0\n",
      "\n",
      "[17118 rows x 4 columns]\n",
      "fold is  4 epoch is  1\n",
      "torch.Size([16, 3, 128, 128])\n",
      "fold is  4 epoch is  2\n",
      "torch.Size([16, 3, 128, 128])\n",
      "             image_id  label                                  path  fold\n",
      "0      1000015157.jpg      0  Datasets/train_images/1000015157.jpg   1.0\n",
      "1      1000201771.jpg      3  Datasets/train_images/1000201771.jpg   1.0\n",
      "2       100042118.jpg      1   Datasets/train_images/100042118.jpg   3.0\n",
      "3      1000723321.jpg      1  Datasets/train_images/1000723321.jpg   1.0\n",
      "4      1000812911.jpg      3  Datasets/train_images/1000812911.jpg   1.0\n",
      "...               ...    ...                                   ...   ...\n",
      "17113   998910982.jpg      1   Datasets/train_images/998910982.jpg   1.0\n",
      "17114   999068805.jpg      3   Datasets/train_images/999068805.jpg   3.0\n",
      "17115   999329392.jpg      3   Datasets/train_images/999329392.jpg   3.0\n",
      "17116   999474432.jpg      1   Datasets/train_images/999474432.jpg   1.0\n",
      "17117   999616605.jpg      4   Datasets/train_images/999616605.jpg   0.0\n",
      "\n",
      "[17118 rows x 4 columns]\n",
      "fold is  5 epoch is  1\n",
      "torch.Size([16, 3, 128, 128])\n",
      "fold is  5 epoch is  2\n",
      "torch.Size([16, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "sk = StratifiedKFold(n_splits=5, random_state=23, shuffle=True)\n",
    "\n",
    "for fold, (train, val) in enumerate(sk.split(train_df, train_df.label)):\n",
    "    train_df.loc[val, 'fold'] = fold\n",
    "    #reset the index after filtering the df based on fold numbers\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_data, transform=data_transform)\n",
    "    val_dataset = CassavaDataset(val_data, transform=data_transform)\n",
    "\n",
    "    train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(train_data)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"fold is \", fold+1,\"epoch is \", epoch+1)\n",
    "        for x_batch, y_batch in train_dl:\n",
    "                print(x_batch.shape)\n",
    "                break\n",
    "\n",
    "    \n",
    "    \n",
    "#train_df.fold = train_df.fold.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Datasets/train_images/1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Datasets/train_images/1000201771.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Datasets/train_images/100042118.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Datasets/train_images/1000723321.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Datasets/train_images/1000812911.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21392</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Datasets/train_images/999068805.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21393</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Datasets/train_images/999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21394</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Datasets/train_images/999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21395</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Datasets/train_images/999616605.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21396</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Datasets/train_images/999998473.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label                                  path  fold\n",
       "0      1000015157.jpg      0  Datasets/train_images/1000015157.jpg     0\n",
       "1      1000201771.jpg      3  Datasets/train_images/1000201771.jpg     1\n",
       "2       100042118.jpg      1   Datasets/train_images/100042118.jpg     3\n",
       "3      1000723321.jpg      1  Datasets/train_images/1000723321.jpg     0\n",
       "4      1000812911.jpg      3  Datasets/train_images/1000812911.jpg     1\n",
       "...               ...    ...                                   ...   ...\n",
       "21392   999068805.jpg      3   Datasets/train_images/999068805.jpg     2\n",
       "21393   999329392.jpg      3   Datasets/train_images/999329392.jpg     3\n",
       "21394   999474432.jpg      1   Datasets/train_images/999474432.jpg     1\n",
       "21395   999616605.jpg      4   Datasets/train_images/999616605.jpg     0\n",
       "21396   999998473.jpg      4   Datasets/train_images/999998473.jpg     3\n",
       "\n",
       "[21397 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "for fold in range(num_folds):\n",
    "\n",
    "    train_df = split_dataset_kfold(train_df, num_folds)\n",
    "\n",
    "    train_data = train_df[train_df['fold'] != fold]\n",
    "    val_data = train_df[train_df['fold'] == fold]\n",
    "    \n",
    "    # Create PyTorch datasets\n",
    "    train_dataset = CassavaDataset(train_data, transform=data_transform)\n",
    "    val_dataset = CassavaDataset(val_data, transform=data_transform)\n",
    "    \n",
    "    # Create PyTorch data loaders\n",
    "    train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    #with Progress() as progress:\n",
    "        #training_task = progress.add_task(\"[red]Training...\", total=num_epochs*len(train_dl))\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
